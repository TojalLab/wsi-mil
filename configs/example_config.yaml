
common:
    results_dir: 'results'  
    dataset_tag: 'DSNAME'
    dataset_metadata: 'inputs/example_metadata.tsv' # input file containing the dataset name, slide metadata and slide target. See inputs/example_metadata.tsv for example


    target_label: 'target_var' # Column name of the target variable containing the classes of the slide. You can use NaN to skip a slide for a given target
    num_workers: 16
    rerun_existing_output: False    # If false, skips re-running results already available in its output directory

create_tiles:   # INSTRUCTIONS FOR THE CREATE_TILES STEP
    input: ${common.dataset_metadata}   
    output:
        tiles: ${common.results_dir}/tiles
        masks: ${common.results_dir}/masks
        metadata: ${common.results_dir}/${common.dataset_tag}_tiles_metadata.csv
    tile_size: 256
    step_size: 128
    ignore_mpp: False
    target_mpp: 0.5
    remove_tiles: 'BRCATU'          # The neural network to run the preprocessing step. Other available options: 9tissues
    remove_tiles_labels_exclude:    # Pre-filtering Neural network classes to skip, removing them from the dataset
        - BG                        # In this example, BG is a class generated by BRCATU when tiles are classified as Background
        - NT
    min_tiles: 1000

extract_features:   # INSTRUCTIONS FOR THE FEATURE EXTRACTION STEP
    input:
        metadata: ${create_tiles.output.metadata}
        tiles: ${create_tiles.output.tiles}
        color_norm:
    output:
        features: ${common.results_dir}/features/${..torchvision_model}/${..feature_layer}/
    torchvision_model: 'resnet50+RetCCL'
    feature_layer: 'avgpool'
    batch_size: 128

splits:             # INSTRUCTIONS FOR THE SPLIT STEP
    input: ${create_tiles.output.metadata}
    output: ${common.results_dir}/splits_${common.dataset_tag}_${common.target_label}_nf${.n_folds}_p${.valid_perc}.csv
    n_folds: 10                     # Number of folds required
    valid_perc: 0.15                # Percentage of slides in the validation set


train_many:         # INSTRUCTIONS FOR TRAINING SEVERAL MODELS
    models: ['target_var', 'target_var 2'] # List all column names of the target variable to be trained. These are the groups defined in the metadata file

train_model:        # INSTRUCTIONS FOR TRAINING THE MODEL
    input:
        metadata: ${splits.output}
        features: ${extract_features.output.features}

    output:
        logging: ${common.results_dir}/train_logs/${common.target_label}/${..model_type}/

    model_type: 'CLAM_MB'

    dataset:
        fold: all
        augmented_sample: False
        weighted_sample: 'oversample'
        shuffle_inst: True
        downsample: NULL
        dropout: 0.3

    trainer:
        max_epochs: 200
        accelerator: 'gpu'
        accumulate_grad_batches: 10
        gradient_clip_val: NULL
        early_stopping: True
        early_stopping_patience: 20
        precision: 16

    model:
        weighted_loss: False
        label_smoothing: 0.0

    CLAM:
        subtyping: True
        bag_loss: 'ce'
        inst_loss: 'svm'
        model_size: 'big2'
        bag_weight: 0.7
        B: 8
        dropout: True
        learning_rate: 2e-4
        weight_decay: 1e-4
        optim: 'adam'
        sched: NULL

inference:      # INSTRUCTIONS FOR RUNNING INFERENCE -- this is often unnecessary as, during training, inference results will be saved in the /checkpoints folder.
    input:
        tiles: ${create_tiles.output.tiles}
        metadata: ${create_tiles.output.metadata}
        model_checkpoint: ${common.results_dir}/checkpoints/run_id/checkpoint_name.ckpt
    output:
        preds: ${common.results_dir}/inference/preds

att_heatmaps:
    input:
        tiles: ${create_tiles.output.tiles}
        metadata: ${splits.output}
        model_checkpoint: ${common.results_dir}/checkpoints/run_id/checkpoint_name.ckpt
    output:
        preds: ${common.results_dir}/att_maps/preds
        overlay: ${common.results_dir}/att_maps/overlay
        side_by_side: ${common.results_dir}/att_maps/side_by_side
    gamma: 1
    alpha_blend: 0.4
    cmap: 'turbo'
    thumbnail_size: [2000,1600]
